{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKHent4AHiyz"
      },
      "outputs": [],
      "source": [
        "Statistics Part 2: Assignment Questions\n",
        "Theoretical Part\n",
        "Here are the answers to the theoretical questions:\n",
        "\n",
        "1. What is hypothesis testing in statistics?\n",
        "Hypothesis testing in statistics is a formal procedure for investigating our ideas about the world using statistics. It is a way to test the results of a survey or experiment to see if you have meaningful results. It involves setting up two competing hypotheses: a null hypothesis and an alternative hypothesis.\n",
        "\n",
        "\n",
        "2. What is the null hypothesis, and how does it differ from the alternative hypothesis?\n",
        "The null hypothesis (\n",
        "\n",
        "H_0) is a statement of no effect or no difference. It's the hypothesis that the researcher is trying to disprove. The alternative hypothesis (\n",
        "\n",
        "H_1 or H_a) is a statement that there is an effect or a difference, and it is what the researcher is trying to prove. For example, if we are testing a new drug, the null hypothesis might be that the drug has no effect, while the alternative hypothesis would be that the drug does have an effect.\n",
        "\n",
        "3. What is the significance level in hypothesis testing, and why is it important?\n",
        "The significance level (\n",
        "\n",
        "alpha) in hypothesis testing is the probability of rejecting the null hypothesis when it is actually true. It is also known as the Type I error rate. Common significance levels are 0.05 (5%), 0.01 (1%), or 0.10 (10%). It is important because it sets the threshold for how strong the evidence must be against the null hypothesis to reject it. A smaller significance level means more evidence is required.\n",
        "\n",
        "\n",
        "4. What does a P-value represent in hypothesis testing?\n",
        "A P-value in hypothesis testing represents the probability of obtaining test results at least as extreme as the observed results, assuming that the null hypothesis is true. It quantifies the strength of evidence against the null hypothesis.\n",
        "\n",
        "5. How do you interpret the P-value in hypothesis testing?\n",
        "Interpreting the P-value involves comparing it to the pre-determined significance level (\n",
        "\n",
        "alpha).\n",
        "\n",
        "If P-value\n",
        "\n",
        "le\n",
        "alpha: We reject the null hypothesis, concluding that there is sufficient evidence to support the alternative hypothesis.\n",
        "\n",
        "If P-value\n",
        "\n",
        "alpha: We fail to reject the null hypothesis, meaning there is not enough evidence to support the alternative hypothesis.\n",
        "\n",
        "6. What are Type 1 and Type 2 errors in hypothesis testing?\n",
        "\n",
        "\n",
        "Type I error (False Positive): Occurs when we reject the null hypothesis when it is actually true. The probability of a Type I error is denoted by\n",
        "\n",
        "alpha (the significance level).\n",
        "\n",
        "\n",
        "Type II error (False Negative): Occurs when we fail to reject the null hypothesis when it is actually false. The probability of a Type II error is denoted by\n",
        "\n",
        "beta.\n",
        "\n",
        "7. What is the difference between a one-tailed and a two-tailed test in hypothesis testing?\n",
        "The difference lies in the alternative hypothesis and the region of rejection.\n",
        "\n",
        "\n",
        "One-tailed test: The alternative hypothesis specifies a direction (e.g., the new drug increases blood pressure, or the new drug decreases blood pressure). The rejection region is entirely in one tail of the distribution.\n",
        "\n",
        "\n",
        "Two-tailed test: The alternative hypothesis does not specify a direction (e.g., the new drug changes blood pressure). The rejection region is split between both tails of the distribution.\n",
        "\n",
        "8. What is the Z-test, and when is it used in hypothesis testing?\n",
        "The Z-test is a statistical test used to determine whether two population means are different when the variances are known and the sample size is large (typically\n",
        "\n",
        "n\n",
        "ge30). It's based on the standard normal distribution.\n",
        "\n",
        "9. How do you calculate the Z-score, and what does it represent in hypothesis testing?\n",
        "The Z-score is calculated as:\n",
        "Z=\n",
        "frac(x−mu)sigma\n",
        "where:\n",
        "\n",
        "x is the sample mean\n",
        "\n",
        "mu is the population mean\n",
        "\n",
        "sigma is the population standard deviation\n",
        "The Z-score represents how many standard deviations an element is from the mean. In hypothesis testing, it indicates how many standard errors the sample mean is from the hypothesized population mean under the null hypothesis.\n",
        "\n",
        "10. What is the T-distribution, and when should it be used instead of the normal distribution?\n",
        "The T-distribution (Student's T-distribution) is a probability distribution that arises when estimating the mean of a normally distributed population in situations where the sample size is small and the population's standard deviation is unknown. It should be used instead of the normal distribution when:\n",
        "\n",
        "The sample size is small (typically\n",
        "\n",
        "$n \\< 30$).\n",
        "\n",
        "The population standard deviation is unknown.\n",
        "\n",
        "11. What is the difference between a Z-test and a T-test?\n",
        "The main differences between a Z-test and a T-test are:\n",
        "\n",
        "\n",
        "Known vs. Unknown Population Standard Deviation: A Z-test is used when the population standard deviation is known, while a T-test is used when it is unknown and estimated from the sample.\n",
        "\n",
        "\n",
        "Sample Size: A Z-test is generally preferred for large sample sizes (n\n",
        "ge30), while a T-test is more appropriate for small sample sizes ($n \\< 30$).\n",
        "\n",
        "\n",
        "Distribution: A Z-test follows a standard normal distribution, while a T-test follows a T-distribution with degrees of freedom.\n",
        "\n",
        "12. What is the T-test, and how is it used in hypothesis testing?\n",
        "The T-test is a statistical hypothesis test used to determine if there is a significant difference between the means of two groups, or between a sample mean and a known population mean, when the population standard deviation is unknown and/or the sample size is small. It's commonly used to compare means of independent or dependent samples.\n",
        "\n",
        "13. What is the relationship between Z-test and T-test in hypothesis testing?\n",
        "Both Z-tests and T-tests are parametric hypothesis tests used to compare means. The T-distribution approaches the standard normal (Z) distribution as the sample size increases. Essentially, the T-test is a more robust version of the Z-test for situations with smaller sample sizes and unknown population standard deviations. If the sample size is large, the results of a T-test will be very similar to a Z-test.\n",
        "\n",
        "14. What is a confidence interval, and how is it used to interpret statistical results?\n",
        "A confidence interval (CI) is a range of values, derived from sample data, that is likely to contain the true population parameter with a certain level of confidence. For example, a 95% confidence interval for the mean means that if we were to take many samples and construct a confidence interval from each, about 95% of these intervals would contain the true population mean. It is used to interpret statistical results by providing a range of plausible values for the population parameter, rather than just a single point estimate. If the confidence interval does not contain a specific value (e.g., zero for a difference in means), it suggests that the true parameter is unlikely to be that value.\n",
        "\n",
        "15. What is the margin of error, and how does it affect the confidence interval?\n",
        "The margin of error (MOE) is the range around a sample statistic (like the sample mean) that estimates the variability in that statistic. It quantifies the precision of the estimate. A confidence interval is typically calculated as the point estimate plus or minus the margin of error. A larger margin of error results in a wider confidence interval, indicating less precision in the estimate, while a smaller margin of error leads to a narrower confidence interval, indicating greater precision. The margin of error is influenced by the sample size, the variability of the data, and the chosen confidence level.\n",
        "\n",
        "16. How is Bayes' Theorem used in statistics, and what is its significance?\n",
        "Bayes' Theorem describes the probability of an event, based on prior knowledge of conditions that might be related to the event. It is expressed as:\n",
        "\n",
        "\n",
        "$P(A|B) = \\\\frac{(P(B|A) \\* P(A))}{P(B)}$\n",
        "where:\n",
        "\n",
        "P(A∣B) is the posterior probability of event A given event B.\n",
        "\n",
        "P(B∣A) is the likelihood of event B given event A.\n",
        "\n",
        "P(A) is the prior probability of event A.\n",
        "\n",
        "P(B) is the marginal probability of event B.\n",
        "Its significance in statistics lies in its ability to update probabilities as new evidence becomes available, forming the basis of Bayesian inference. This approach allows for the incorporation of prior beliefs into the analysis, which can be particularly useful when data is scarce or when subjective expertise is valuable.\n",
        "\n",
        "17. What is the Chi-square distribution, and when is it used?\n",
        "The Chi-square (\n",
        "\n",
        "chi\n",
        "2\n",
        " ) distribution is a non-negative, positively skewed distribution that is used in hypothesis testing. It is primarily used when:\n",
        "\n",
        "Testing for independence between two categorical variables (Chi-square test of independence).\n",
        "\n",
        "Testing for the goodness of fit of observed data to an expected distribution (Chi-square goodness-of-fit test).\n",
        "\n",
        "Estimating confidence intervals for population variance or standard deviation.\n",
        "\n",
        "18. What is the Chi-square goodness of fit test, and how is it applied?\n",
        "The Chi-square goodness-of-fit test is used to determine whether an observed frequency distribution differs significantly from an expected frequency distribution. It is applied by:\n",
        "\n",
        "Stating the null and alternative hypotheses. The null hypothesis is that there is no significant difference between the observed and expected distributions.\n",
        "\n",
        "Calculating the Chi-square test statistic using the formula:\n",
        "chi\n",
        "2\n",
        " =\n",
        "sum\n",
        "frac((O_i−E_i)\n",
        "2\n",
        " )E_i\n",
        "where O_i are the observed frequencies and E_i are the expected frequencies.\n",
        "\n",
        "Determining the degrees of freedom.\n",
        "\n",
        "Comparing the calculated\n",
        "\n",
        "chi\n",
        "2\n",
        "  value to the critical value from the Chi-square distribution table or using the P-value.\n",
        "\n",
        "Making a decision to reject or fail to reject the null hypothesis based on the comparison.\n",
        "\n",
        "19. What is the F-distribution, and when is it used in hypothesis testing?\n",
        "The F-distribution is a continuous probability distribution that arises in the testing of hypotheses concerning two variances or in the analysis of variance (ANOVA). It is used in hypothesis testing primarily when:\n",
        "\n",
        "Comparing the variances of two populations (F-test for equality of variances).\n",
        "\n",
        "Comparing the means of three or more groups (ANOVA).\n",
        "\n",
        "20. What is an ANOVA test, and what are its assumptions?\n",
        "ANOVA (Analysis of Variance) is a statistical test used to compare the means of three or more groups to determine if there is a statistically significant difference between them. Instead of performing multiple t-tests (which would increase the chance of Type I error), ANOVA tests the null hypothesis that all group means are equal.\n",
        "\n",
        "\n",
        "Its assumptions are:\n",
        "\n",
        "\n",
        "Independence of observations: The observations within each group and across groups must be independent.\n",
        "\n",
        "\n",
        "Normality: The data in each group should be approximately normally distributed.\n",
        "\n",
        "\n",
        "Homoscedasticity (homogeneity of variances): The variances of the populations from which the samples are drawn should be equal.\n",
        "\n",
        "21. What are the different types of ANOVA tests?\n",
        "The different types of ANOVA tests include:\n",
        "\n",
        "\n",
        "One-Way ANOVA: Used when there is one independent categorical variable (factor) and one dependent continuous variable. It compares the means of three or more independent groups.\n",
        "\n",
        "\n",
        "Two-Way ANOVA: Used when there are two independent categorical variables (factors) and one dependent continuous variable. It examines the main effects of each factor and their interaction effect.\n",
        "\n",
        "\n",
        "N-Way ANOVA (Multi-factor ANOVA): An extension of two-way ANOVA to more than two independent categorical variables.\n",
        "\n",
        "\n",
        "Repeated Measures ANOVA: Used when the same subjects are measured multiple times under different conditions or at different time points.\n",
        "\n",
        "\n",
        "MANOVA (Multivariate Analysis of Variance): Used when there are two or more dependent continuous variables and one or more independent categorical variables.\n",
        "\n",
        "22. What is the F-test, and how does it relate to hypothesis testing?\n",
        "The F-test is any statistical test that uses the F-distribution under the null hypothesis. In hypothesis testing, it is primarily used to:\n",
        "\n",
        "\n",
        "Compare variances: To test if two population variances are equal.\n",
        "\n",
        "\n",
        "ANOVA: To test the overall significance of the model in ANOVA by comparing the variance between group means to the variance within the groups. If the F-statistic is large, it suggests that the variation between group means is greater than the variation within groups, leading to the rejection of the null hypothesis that all group means are equal.\n",
        "\n",
        "Practical Part - 1\n",
        "Here are the Python programs for the practical part:\n",
        "\n",
        "1. Write a Python program to generate a random variable and display its value.\n",
        "\n",
        "Python\n",
        "\n",
        "import random\n",
        "\n",
        "# Generate a random integer between 1 and 100\n",
        "random_variable = random.randint(1, 100)\n",
        "print(f\"Generated random variable: {random_variable}\")\n",
        "2. Generate a discrete uniform distribution using Python and plot the probability mass function (PMF).\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Define the range for the discrete uniform distribution\n",
        "low = 1\n",
        "high = 6  # e.g., simulating a fair die\n",
        "\n",
        "# Generate random samples from a discrete uniform distribution\n",
        "# rvs stands for random variates\n",
        "data_discrete_uniform = uniform.rvs(loc=low, scale=high - low + 1, size=1000)\n",
        "\n",
        "# Calculate PMF (proportion of each value)\n",
        "unique_values, counts = np.unique(data_discrete_uniform, return_counts=True)\n",
        "pmf = counts / len(data_discrete_uniform)\n",
        "\n",
        "# Plot the PMF\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.bar(unique_values, pmf, color='skyblue', edgecolor='black')\n",
        "plt.title('Probability Mass Function (PMF) of Discrete Uniform Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability')\n",
        "plt.xticks(unique_values)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "3. Write a Python function to calculate the probability distribution function (PDF) of a Bernoulli distribution.\n",
        "\n",
        "Note: For a Bernoulli distribution, we talk about the Probability Mass Function (PMF) since it's a discrete distribution, not PDF.\n",
        "\n",
        "Python\n",
        "\n",
        "def bernoulli_pmf(p, k):\n",
        "    \"\"\"\n",
        "    Calculates the Probability Mass Function (PMF) of a Bernoulli distribution.\n",
        "\n",
        "    Args:\n",
        "        p (float): The probability of success (between 0 and 1).\n",
        "        k (int): The outcome (0 for failure, 1 for success).\n",
        "\n",
        "    Returns:\n",
        "        float: The probability of the given outcome.\n",
        "    \"\"\"\n",
        "    if not (0 <= p <= 1):\n",
        "        raise ValueError(\"Probability 'p' must be between 0 and 1.\")\n",
        "    if not (k == 0 or k == 1):\n",
        "        raise ValueError(\"Outcome 'k' must be either 0 (failure) or 1 (success).\")\n",
        "\n",
        "    if k == 1:\n",
        "        return p\n",
        "    elif k == 0:\n",
        "        return 1 - p\n",
        "\n",
        "# Example usage:\n",
        "p_success = 0.7\n",
        "prob_success = bernoulli_pmf(p_success, 1)\n",
        "prob_failure = bernoulli_pmf(p_success, 0)\n",
        "\n",
        "print(f\"Probability of success (k=1) with p={p_success}: {prob_success}\")\n",
        "print(f\"Probability of failure (k=0) with p={p_success}: {prob_failure}\")\n",
        "4. Write a Python script to simulate a binomial distribution with n=10 and p=0.5, then plot its histogram.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters for binomial distribution\n",
        "n = 10  # Number of trials\n",
        "p = 0.5 # Probability of success\n",
        "\n",
        "# Simulate data from binomial distribution\n",
        "# rvs(n, p, size) generates random variates\n",
        "simulated_data = binom.rvs(n=n, p=p, size=1000)\n",
        "\n",
        "# Plot the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(simulated_data, bins=np.arange(-0.5, n + 1.5, 1), edgecolor='black', alpha=0.7, density=True)\n",
        "plt.title(f'Histogram of Binomial Distribution (n={n}, p={p})')\n",
        "plt.xlabel('Number of Successes')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.xticks(np.arange(0, n + 1, 1))\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "5. Create a Poisson distribution and visualize it using Python.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "# Parameter for Poisson distribution (lambda = average number of events)\n",
        "lambda_val = 3\n",
        "\n",
        "# Simulate data from Poisson distribution\n",
        "simulated_data_poisson = poisson.rvs(mu=lambda_val, size=1000)\n",
        "\n",
        "# Calculate PMF for visualization\n",
        "k_values = np.arange(0, np.max(simulated_data_poisson) + 2)\n",
        "pmf_values = poisson.pmf(k_values, mu=lambda_val)\n",
        "\n",
        "# Plot the PMF and histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Histogram of simulated data\n",
        "plt.hist(simulated_data_poisson, bins=np.arange(-0.5, np.max(simulated_data_poisson) + 1.5, 1),\n",
        "         edgecolor='black', alpha=0.6, density=True, label='Simulated Data Histogram')\n",
        "\n",
        "# PMF overlay\n",
        "plt.plot(k_values, pmf_values, 'ro-', label='Poisson PMF')\n",
        "\n",
        "plt.title(f'Poisson Distribution (λ={lambda_val})')\n",
        "plt.xlabel('Number of Events')\n",
        "plt.ylabel('Probability / Density')\n",
        "plt.xticks(k_values)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "6. Write a Python program to calculate and plot the cumulative distribution function (CDF) of a discrete uniform distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import uniform\n",
        "\n",
        "# Define the range for the discrete uniform distribution\n",
        "low = 1\n",
        "high = 6\n",
        "\n",
        "# Create an array of possible values\n",
        "values = np.arange(low, high + 1)\n",
        "\n",
        "# Calculate the CDF for each value\n",
        "# For discrete uniform, CDF is (k - low + 1) / (high - low + 1)\n",
        "cdf_values = [(k - low + 1) / (high - low + 1) for k in values]\n",
        "\n",
        "# Plot the CDF\n",
        "plt.figure(figsize=(8, 6))\n",
        "plt.step(values, cdf_values, where='post', color='blue', linestyle='-', marker='o', markersize=6)\n",
        "plt.title('Cumulative Distribution Function (CDF) of Discrete Uniform Distribution')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('CDF')\n",
        "plt.xticks(values)\n",
        "plt.yticks(np.linspace(0, 1, len(values) + 1))\n",
        "plt.grid(axis='both', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "7. Generate a continuous uniform distribution using NumPy and visualize it.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Define the range for the continuous uniform distribution\n",
        "a = 0  # lower bound\n",
        "b = 10 # upper bound\n",
        "\n",
        "# Generate random samples from a continuous uniform distribution\n",
        "num_samples = 10000\n",
        "data_continuous_uniform = np.random.uniform(low=a, high=b, size=num_samples)\n",
        "\n",
        "# Visualize the distribution using a histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data_continuous_uniform, bins=50, density=True, alpha=0.7, color='lightgreen', edgecolor='black',\n",
        "         label=f'Simulated Data (n={num_samples})')\n",
        "\n",
        "# Plot the theoretical PDF for a continuous uniform distribution\n",
        "# PDF is 1/(b-a) for a <= x <= b, and 0 otherwise\n",
        "x = np.linspace(a - 1, b + 1, 500)\n",
        "pdf_theoretical = np.where((x >= a) & (x <= b), 1 / (b - a), 0)\n",
        "plt.plot(x, pdf_theoretical, color='red', linestyle='--', linewidth=2, label='Theoretical PDF')\n",
        "\n",
        "plt.title(f'Continuous Uniform Distribution between {a} and {b}')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "8. Simulate data from a normal distribution and plot its histogram.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Parameters for the normal distribution\n",
        "mean = 50\n",
        "std_dev = 10\n",
        "num_samples = 10000\n",
        "\n",
        "# Simulate data from a normal distribution\n",
        "data_normal = np.random.normal(loc=mean, scale=std_dev, size=num_samples)\n",
        "\n",
        "# Plot the histogram\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(data_normal, bins=50, density=True, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "plt.title(f'Histogram of Normal Distribution (Mean={mean}, Std Dev={std_dev})')\n",
        "plt.xlabel('Value')\n",
        "plt.ylabel('Probability Density')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.show()\n",
        "9. Write a Python function to calculate Z-scores from a dataset and plot them.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_and_plot_zscores(data):\n",
        "    \"\"\"\n",
        "    Calculates Z-scores for a given dataset and plots their histogram along\n",
        "    with the standard normal distribution PDF.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The dataset for which to calculate Z-scores.\n",
        "    \"\"\"\n",
        "    data = np.array(data)\n",
        "    mean = np.mean(data)\n",
        "    std_dev = np.std(data)\n",
        "\n",
        "    if std_dev == 0:\n",
        "        print(\"Standard deviation is zero. Cannot calculate Z-scores.\")\n",
        "        return\n",
        "\n",
        "    z_scores = (data - mean) / std_dev\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(z_scores, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black', label='Z-scores Histogram')\n",
        "\n",
        "    # Plot the standard normal distribution PDF for comparison\n",
        "    x = np.linspace(-4, 4, 1000)\n",
        "    pdf_standard_normal = norm.pdf(x, 0, 1)\n",
        "    plt.plot(x, pdf_standard_normal, color='red', linestyle='--', linewidth=2, label='Standard Normal PDF (μ=0, σ=1)')\n",
        "\n",
        "    plt.title('Distribution of Z-scores and Standard Normal PDF')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return z_scores\n",
        "\n",
        "# Example usage with simulated data:\n",
        "np.random.seed(42) # for reproducibility\n",
        "sample_data = np.random.normal(loc=70, scale=15, size=500)\n",
        "calculated_z_scores = calculate_and_plot_zscores(sample_data)\n",
        "print(f\"First 10 Z-scores: {calculated_z_scores[:10]}\")\n",
        "10. Implement the Central Limit Theorem (CLT) using Python for a non-normal distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import expon # Using exponential distribution as a non-normal example\n",
        "\n",
        "# Parameters for the non-normal distribution (e.g., Exponential distribution)\n",
        "lambda_exp = 0.5 # Rate parameter for exponential distribution\n",
        "population_mean_exp = 1 / lambda_exp # Theoretical mean of exponential distribution\n",
        "population_std_exp = 1 / lambda_exp # Theoretical standard deviation of exponential distribution\n",
        "\n",
        "# Number of samples to draw for each experiment\n",
        "num_samples_per_experiment = 30 # Sample size (n >= 30 for CLT to work well)\n",
        "num_experiments = 10000        # Number of times to repeat the sampling process\n",
        "\n",
        "# Simulate sampling from the exponential distribution and calculate sample means\n",
        "sample_means = []\n",
        "for _ in range(num_experiments):\n",
        "    # Draw a sample from the exponential distribution\n",
        "    sample = expon.rvs(scale=1/lambda_exp, size=num_samples_per_experiment)\n",
        "    # Calculate the mean of the sample\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Plot the histogram of sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sample_means, bins=50, density=True, alpha=0.7, color='teal', edgecolor='black')\n",
        "\n",
        "# Overlay the theoretical normal distribution predicted by CLT\n",
        "# Mean of sample means should be close to population mean\n",
        "clt_mean = population_mean_exp\n",
        "# Standard deviation of sample means (Standard Error) = Population Std Dev / sqrt(n)\n",
        "clt_std = population_std_exp / np.sqrt(num_samples_per_experiment)\n",
        "\n",
        "x = np.linspace(min(sample_means), max(sample_means), 1000)\n",
        "pdf_clt = norm.pdf(x, clt_mean, clt_std)\n",
        "plt.plot(x, pdf_clt, color='red', linestyle='--', linewidth=2, label='Normal Distribution (CLT Prediction)')\n",
        "\n",
        "plt.title(f'Central Limit Theorem Demonstration (Non-Normal Population)\\n'\n",
        "          f'Sample Size per Experiment: {num_samples_per_experiment}, Number of Experiments: {num_experiments}')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Theoretical Population Mean (Exponential): {population_mean_exp:.2f}\")\n",
        "print(f\"Empirical Mean of Sample Means: {np.mean(sample_means):.2f}\")\n",
        "print(f\"Theoretical Standard Error (CLT): {clt_std:.2f}\")\n",
        "print(f\"Empirical Standard Deviation of Sample Means: {np.std(sample_means):.2f}\")\n",
        "Practical Part - 2\n",
        "11. Simulate multiple samples from a normal distribution and verify the Central Limit Theorem.\n",
        "\n",
        "This question is similar to Q10 in \"Practical Part 1\" but specifically for a normal distribution. While CLT is most striking for non-normal distributions, it also holds for normal ones, showing that the distribution of sample means becomes even more precisely normal.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "# Parameters for the normal population\n",
        "population_mean = 100\n",
        "population_std = 15\n",
        "\n",
        "# Number of samples to draw for each experiment\n",
        "num_samples_per_experiment = 20 # Even for normal, CLT still applies, but 20 is just an example\n",
        "num_experiments = 10000\n",
        "\n",
        "# Simulate sampling from the normal distribution and calculate sample means\n",
        "sample_means = []\n",
        "for _ in range(num_experiments):\n",
        "    sample = np.random.normal(loc=population_mean, scale=population_std, size=num_samples_per_experiment)\n",
        "    sample_means.append(np.mean(sample))\n",
        "\n",
        "# Plot the histogram of sample means\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(sample_means, bins=50, density=True, alpha=0.7, color='purple', edgecolor='black')\n",
        "\n",
        "# Overlay the theoretical normal distribution predicted by CLT\n",
        "clt_mean = population_mean\n",
        "clt_std = population_std / np.sqrt(num_samples_per_experiment)\n",
        "\n",
        "x = np.linspace(min(sample_means), max(sample_means), 1000)\n",
        "pdf_clt = norm.pdf(x, clt_mean, clt_std)\n",
        "plt.plot(x, pdf_clt, color='red', linestyle='--', linewidth=2, label='Normal Distribution (CLT Prediction)')\n",
        "\n",
        "plt.title(f'Central Limit Theorem Demonstration (Normal Population)\\n'\n",
        "          f'Sample Size per Experiment: {num_samples_per_experiment}, Number of Experiments: {num_experiments}')\n",
        "plt.xlabel('Sample Mean')\n",
        "plt.ylabel('Density')\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "print(f\"Theoretical Population Mean: {population_mean:.2f}\")\n",
        "print(f\"Empirical Mean of Sample Means: {np.mean(sample_means):.2f}\")\n",
        "print(f\"Theoretical Standard Error (CLT): {clt_std:.2f}\")\n",
        "print(f\"Empirical Standard Deviation of Sample Means: {np.std(sample_means):.2f}\")\n",
        "12. Write a Python function to calculate and plot the standard normal distribution (mean=0,std=1).\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_standard_normal_distribution():\n",
        "    \"\"\"\n",
        "    Calculates and plots the Probability Density Function (PDF)\n",
        "    of the standard normal distribution (mean=0, std=1).\n",
        "    \"\"\"\n",
        "    mean = 0\n",
        "    std_dev = 1\n",
        "\n",
        "    # Generate x values\n",
        "    x = np.linspace(-4, 4, 500) # Range from -4 to 4 standard deviations\n",
        "\n",
        "    # Calculate the PDF values\n",
        "    pdf_values = norm.pdf(x, loc=mean, scale=std_dev)\n",
        "\n",
        "    # Plot the PDF\n",
        "    plt.figure(figsize=(9, 6))\n",
        "    plt.plot(x, pdf_values, color='blue', linewidth=2)\n",
        "    plt.title('Standard Normal Distribution (Mean=0, Std Dev=1)')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Probability Density Function (PDF)')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.axvline(x=0, color='gray', linestyle=':', label='Mean = 0')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Call the function to plot\n",
        "plot_standard_normal_distribution()\n",
        "13. Generate random variables and calculate their corresponding probabilities using the binomial distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import binom\n",
        "\n",
        "# Parameters for binomial distribution\n",
        "n = 20  # Number of trials\n",
        "p = 0.4 # Probability of success\n",
        "\n",
        "# Generate some random variables (number of successes)\n",
        "num_random_variables = 5\n",
        "random_successes = np.random.randint(low=0, high=n + 1, size=num_random_variables)\n",
        "\n",
        "print(f\"Binomial Distribution Parameters: n={n}, p={p}\")\n",
        "print(\"---\")\n",
        "\n",
        "# Calculate the probability for each random variable\n",
        "for k in random_successes:\n",
        "    prob = binom.pmf(k, n, p)\n",
        "    print(f\"P(X = {k}) = {prob:.4f}\")\n",
        "\n",
        "print(\"\\n---\")\n",
        "print(\"Also, let's calculate probabilities for a range of possible outcomes:\")\n",
        "# Calculate PMF for all possible outcomes (0 to n)\n",
        "possible_outcomes = np.arange(0, n + 1)\n",
        "probabilities = binom.pmf(possible_outcomes, n, p)\n",
        "\n",
        "for k, prob in zip(possible_outcomes, probabilities):\n",
        "    if prob > 0.001: # Only print probabilities that are somewhat significant\n",
        "        print(f\"P(X = {k}) = {prob:.4f}\")\n",
        "14. Write a Python program to calculate the Z-score for a given data point and compare it to a standard normal distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_and_compare_zscore(data_point, dataset):\n",
        "    \"\"\"\n",
        "    Calculates the Z-score for a given data point within a dataset\n",
        "    and visualizes its position relative to the standard normal distribution.\n",
        "\n",
        "    Args:\n",
        "        data_point (float): The specific data point for which to calculate the Z-score.\n",
        "        dataset (array-like): The dataset from which the mean and std dev are calculated.\n",
        "    \"\"\"\n",
        "    dataset = np.array(dataset)\n",
        "    mean_dataset = np.mean(dataset)\n",
        "    std_dev_dataset = np.std(dataset)\n",
        "\n",
        "    if std_dev_dataset == 0:\n",
        "        print(\"Standard deviation of the dataset is zero. Cannot calculate Z-score.\")\n",
        "        return\n",
        "\n",
        "    z_score = (data_point - mean_dataset) / std_dev_dataset\n",
        "\n",
        "    print(f\"Data Point: {data_point}\")\n",
        "    print(f\"Dataset Mean: {mean_dataset:.2f}\")\n",
        "    print(f\"Dataset Standard Deviation: {std_dev_dataset:.2f}\")\n",
        "    print(f\"Calculated Z-score: {z_score:.4f}\")\n",
        "\n",
        "    # Plotting the standard normal distribution\n",
        "    x = np.linspace(-4, 4, 500)\n",
        "    pdf_standard_normal = norm.pdf(x, 0, 1)\n",
        "\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf_standard_normal, color='blue', linewidth=2, label='Standard Normal PDF')\n",
        "    plt.axvline(x=z_score, color='red', linestyle='--', label=f'Z-score of {data_point:.2f}: {z_score:.2f}')\n",
        "    plt.fill_between(x, 0, pdf_standard_normal, where=(x >= z_score), color='skyblue', alpha=0.3, label=f'P(Z > {z_score:.2f}) = {1 - norm.cdf(z_score):.4f}')\n",
        "    plt.title('Z-score Comparison to Standard Normal Distribution')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "np.random.seed(42)\n",
        "sample_data = np.random.normal(loc=60, scale=8, size=100) # Simulate a dataset\n",
        "data_point_of_interest = 75\n",
        "\n",
        "calculate_and_compare_zscore(data_point_of_interest, sample_data)\n",
        "\n",
        "data_point_of_interest_2 = 50\n",
        "calculate_and_compare_zscore(data_point_of_interest_2, sample_data)\n",
        "15. Implement hypothesis testing using Z-statistics for a sample dataset.\n",
        "\n",
        "This example performs a one-sample Z-test to compare a sample mean to a known population mean.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_test_one_sample(sample_data, population_mean_hypothesized, population_std, alpha):\n",
        "    \"\"\"\n",
        "    Performs a one-sample Z-test for a sample mean against a known population mean.\n",
        "\n",
        "    Args:\n",
        "        sample_data (array-like): The sample data.\n",
        "        population_mean_hypothesized (float): The hypothesized population mean (H0).\n",
        "        population_std (float): The known population standard deviation.\n",
        "        alpha (float): The significance level.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (z_statistic, p_value, decision)\n",
        "    \"\"\"\n",
        "    n = len(sample_data)\n",
        "    sample_mean = np.mean(sample_data)\n",
        "\n",
        "    if population_std == 0:\n",
        "        print(\"Population standard deviation cannot be zero.\")\n",
        "        return None, None, \"Cannot perform test (Std Dev is zero)\"\n",
        "\n",
        "    # Calculate the Z-statistic\n",
        "    z_statistic = (sample_mean - population_mean_hypothesized) / (population_std / np.sqrt(n))\n",
        "\n",
        "    # Calculate the two-tailed P-value\n",
        "    p_value = 2 * (1 - norm.cdf(abs(z_statistic)))\n",
        "\n",
        "    # Make a decision\n",
        "    print(f\"\\n--- Z-Test Results ---\")\n",
        "    print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "    print(f\"Sample Size (n): {n}\")\n",
        "    print(f\"Hypothesized Population Mean (μ0): {population_mean_hypothesized:.2f}\")\n",
        "    print(f\"Known Population Standard Deviation (σ): {population_std:.2f}\")\n",
        "    print(f\"Calculated Z-statistic: {z_statistic:.4f}\")\n",
        "    print(f\"P-value: {p_value:.4f}\")\n",
        "    print(f\"Significance Level (α): {alpha}\")\n",
        "\n",
        "    if p_value < alpha:\n",
        "        decision = \"Reject Null Hypothesis (H0)\"\n",
        "        print(f\"Decision: {decision} (P-value < α)\")\n",
        "        print(f\"Conclusion: There is significant evidence that the sample mean is different from the hypothesized population mean.\")\n",
        "    else:\n",
        "        decision = \"Fail to Reject Null Hypothesis (H0)\"\n",
        "        print(f\"Decision: {decision} (P-value >= α)\")\n",
        "        print(f\"Conclusion: There is not enough evidence to conclude that the sample mean is different from the hypothesized population mean.\")\n",
        "\n",
        "    return z_statistic, p_value, decision\n",
        "\n",
        "# Example Usage:\n",
        "np.random.seed(42)\n",
        "# Simulate a sample from a population with mean 50 and std dev 5\n",
        "sample_data = np.random.normal(loc=51, scale=5, size=40)\n",
        "\n",
        "# Hypothesized population mean\n",
        "hypothesized_mean = 50\n",
        "# Known population standard deviation (assuming it's known)\n",
        "pop_std_dev = 5\n",
        "# Significance level\n",
        "alpha = 0.05\n",
        "\n",
        "z_statistic, p_value, decision = z_test_one_sample(sample_data, hypothesized_mean, pop_std_dev, alpha)\n",
        "\n",
        "# Another example where we might fail to reject H0\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "np.random.seed(43)\n",
        "sample_data_2 = np.random.normal(loc=50.5, scale=5, size=40)\n",
        "z_statistic_2, p_value_2, decision_2 = z_test_one_sample(sample_data_2, hypothesized_mean, pop_std_dev, alpha)\n",
        "16. Create a confidence interval for a dataset using Python and interpret the result.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import norm, t\n",
        "\n",
        "def calculate_and_interpret_confidence_interval(data, confidence_level=0.95, known_population_std=None):\n",
        "    \"\"\"\n",
        "    Calculates and interprets the confidence interval for the mean of a dataset.\n",
        "\n",
        "    Args:\n",
        "        data (array-like): The dataset.\n",
        "        confidence_level (float): The desired confidence level (e.g., 0.95 for 95%).\n",
        "        known_population_std (float, optional): Known population standard deviation.\n",
        "                                                If None, sample standard deviation is used (T-distribution).\n",
        "    Returns:\n",
        "        tuple: (lower_bound, upper_bound) of the confidence interval.\n",
        "    \"\"\"\n",
        "    n = len(data)\n",
        "    sample_mean = np.mean(data)\n",
        "    sample_std = np.std(data, ddof=1) # ddof=1 for sample standard deviation\n",
        "\n",
        "    print(f\"\\n--- Confidence Interval Calculation ---\")\n",
        "    print(f\"Sample Mean: {sample_mean:.2f}\")\n",
        "    print(f\"Sample Size (n): {n}\")\n",
        "    print(f\"Confidence Level: {int(confidence_level * 100)}%\")\n",
        "\n",
        "    if n == 0:\n",
        "        print(\"Cannot calculate confidence interval for an empty dataset.\")\n",
        "        return None, None\n",
        "\n",
        "    if known_population_std is not None:\n",
        "        # Use Z-distribution (Normal distribution)\n",
        "        print(f\"Using Z-distribution (known population standard deviation = {known_population_std:.2f})\")\n",
        "        standard_error = known_population_std / np.sqrt(n)\n",
        "        z_critical = norm.ppf(1 - (1 - confidence_level) / 2)\n",
        "        margin_of_error = z_critical * standard_error\n",
        "        distribution_used = \"Z-distribution\"\n",
        "        critical_value = z_critical\n",
        "    else:\n",
        "        # Use T-distribution (population standard deviation unknown)\n",
        "        print(f\"Using T-distribution (sample standard deviation = {sample_std:.2f})\")\n",
        "        if n == 1:\n",
        "            print(\"Cannot calculate T-confidence interval with only one sample.\")\n",
        "            return None, None\n",
        "        standard_error = sample_std / np.sqrt(n)\n",
        "        degrees_of_freedom = n - 1\n",
        "        t_critical = t.ppf(1 - (1 - confidence_level) / 2, degrees_of_freedom)\n",
        "        margin_of_error = t_critical * standard_error\n",
        "        distribution_used = f\"T-distribution (df={degrees_of_freedom})\"\n",
        "        critical_value = t_critical\n",
        "\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    print(f\"Standard Error: {standard_error:.4f}\")\n",
        "    print(f\"Critical Value ({distribution_used}): {critical_value:.4f}\")\n",
        "    print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "    print(f\"Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "\n",
        "    print(f\"\\nInterpretation: We are {int(confidence_level * 100)}% confident that the true population mean lies within the range of ({lower_bound:.2f}, {upper_bound:.2f}).\")\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage 1: Population standard deviation known (use Z-test logic for CI)\n",
        "np.random.seed(42)\n",
        "data_known_std = np.random.normal(loc=75, scale=10, size=50) # Simulate data\n",
        "known_pop_std = 10 # Assume we know the population standard deviation\n",
        "calculate_and_interpret_confidence_interval(data_known_std, confidence_level=0.95, known_population_std=known_pop_std)\n",
        "\n",
        "# Example usage 2: Population standard deviation unknown (use T-test logic for CI)\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "np.random.seed(43)\n",
        "data_unknown_std = np.random.normal(loc=150, scale=20, size=25) # Smaller sample size\n",
        "calculate_and_interpret_confidence_interval(data_unknown_std, confidence_level=0.90)\n",
        "17. Generate data from a normal distribution, then calculate and interpret the confidence interval for its mean.\n",
        "\n",
        "This is effectively covered by the examples in Q16, but here's a dedicated example for clarity.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import t # Using t-distribution as population std is typically unknown for sampled data\n",
        "\n",
        "def generate_data_and_calculate_ci(population_mean, population_std, sample_size, confidence_level=0.95):\n",
        "    \"\"\"\n",
        "    Generates data from a normal distribution, then calculates and interprets\n",
        "    the confidence interval for its mean.\n",
        "\n",
        "    Args:\n",
        "        population_mean (float): The mean of the normal distribution to generate data from.\n",
        "        population_std (float): The standard deviation of the normal distribution.\n",
        "        sample_size (int): The number of data points to generate.\n",
        "        confidence_level (float): The desired confidence level.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (lower_bound, upper_bound) of the confidence interval.\n",
        "    \"\"\"\n",
        "    print(f\"\\n--- Generating Data and Calculating CI ---\")\n",
        "    print(f\"Population Parameters for Data Generation: Mean={population_mean}, Std Dev={population_std}\")\n",
        "    print(f\"Sample Size: {sample_size}\")\n",
        "    print(f\"Confidence Level: {int(confidence_level * 100)}%\")\n",
        "\n",
        "    # Generate data from a normal distribution\n",
        "    generated_data = np.random.normal(loc=population_mean, scale=population_std, size=sample_size)\n",
        "    print(f\"Generated sample (first 5): {generated_data[:5].round(2)}...\")\n",
        "\n",
        "    n = len(generated_data)\n",
        "    sample_mean = np.mean(generated_data)\n",
        "    sample_std = np.std(generated_data, ddof=1) # Use sample std dev\n",
        "\n",
        "    if n <= 1:\n",
        "        print(\"Cannot calculate confidence interval with less than 2 data points.\")\n",
        "        return None, None\n",
        "    if sample_std == 0:\n",
        "        print(\"Sample standard deviation is zero. Cannot calculate confidence interval.\")\n",
        "        return None, None\n",
        "\n",
        "    # Use T-distribution for confidence interval as population std is unknown (we are estimating it from the sample)\n",
        "    standard_error = sample_std / np.sqrt(n)\n",
        "    degrees_of_freedom = n - 1\n",
        "    t_critical = t.ppf(1 - (1 - confidence_level) / 2, degrees_of_freedom)\n",
        "    margin_of_error = t_critical * standard_error\n",
        "\n",
        "    lower_bound = sample_mean - margin_of_error\n",
        "    upper_bound = sample_mean + margin_of_error\n",
        "\n",
        "    print(f\"\\nSample Mean: {sample_mean:.2f}\")\n",
        "    print(f\"Sample Standard Deviation: {sample_std:.2f}\")\n",
        "    print(f\"Standard Error of the Mean: {standard_error:.4f}\")\n",
        "    print(f\"Degrees of Freedom: {degrees_of_freedom}\")\n",
        "    print(f\"T-critical value: {t_critical:.4f}\")\n",
        "    print(f\"Margin of Error: {margin_of_error:.4f}\")\n",
        "    print(f\"Calculated Confidence Interval: ({lower_bound:.2f}, {upper_bound:.2f})\")\n",
        "\n",
        "    print(f\"\\nInterpretation: We are {int(confidence_level * 100)}% confident that the true population mean (from which this sample was drawn) lies within the range of ({lower_bound:.2f}, {upper_bound:.2f}).\")\n",
        "\n",
        "    return lower_bound, upper_bound\n",
        "\n",
        "# Example usage:\n",
        "np.random.seed(123)\n",
        "generate_data_and_calculate_ci(population_mean=100, population_std=10, sample_size=30, confidence_level=0.95)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "np.random.seed(456)\n",
        "generate_data_and_calculate_ci(population_mean=50, population_std=5, sample_size=15, confidence_level=0.99)\n",
        "18. Write a Python script to calculate and visualize the probability density function (PDF) of a normal distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def plot_normal_pdf(mean, std_dev):\n",
        "    \"\"\"\n",
        "    Calculates and visualizes the Probability Density Function (PDF)\n",
        "    of a normal distribution given its mean and standard deviation.\n",
        "\n",
        "    Args:\n",
        "        mean (float): The mean of the normal distribution.\n",
        "        std_dev (float): The standard deviation of the normal distribution.\n",
        "    \"\"\"\n",
        "    if std_dev <= 0:\n",
        "        raise ValueError(\"Standard deviation must be positive.\")\n",
        "\n",
        "    # Generate x values, typically from mean - 4*std_dev to mean + 4*std_dev\n",
        "    x = np.linspace(mean - 4 * std_dev, mean + 4 * std_dev, 500)\n",
        "\n",
        "    # Calculate the PDF values\n",
        "    pdf_values = norm.pdf(x, loc=mean, scale=std_dev)\n",
        "\n",
        "    # Plot the PDF\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(x, pdf_values, color='darkgreen', linewidth=2)\n",
        "    plt.title(f'Probability Density Function (PDF) of Normal Distribution\\nMean={mean}, Std Dev={std_dev}')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Probability Density')\n",
        "    plt.grid(True, linestyle='--', alpha=0.7)\n",
        "    plt.axvline(x=mean, color='red', linestyle=':', label='Mean')\n",
        "    plt.fill_between(x, 0, pdf_values, color='lightgreen', alpha=0.3, label='Area under curve = 1')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Example usage:\n",
        "plot_normal_pdf(mean=0, std_dev=1) # Standard Normal\n",
        "plot_normal_pdf(mean=50, std_dev=10)\n",
        "plot_normal_pdf(mean=100, std_dev=5)\n",
        "19. Use Python to calculate and interpret the cumulative distribution function (CDF) of a Poisson distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import poisson\n",
        "\n",
        "def calculate_and_interpret_poisson_cdf(lambda_val, k_value=None):\n",
        "    \"\"\"\n",
        "    Calculates and interprets the Cumulative Distribution Function (CDF)\n",
        "    of a Poisson distribution.\n",
        "\n",
        "    Args:\n",
        "        lambda_val (float): The average rate of events (lambda) for the Poisson distribution.\n",
        "        k_value (int, optional): A specific integer k for which to calculate P(X <= k).\n",
        "                                 If None, plots the CDF for a range of values.\n",
        "    \"\"\"\n",
        "    if lambda_val <= 0:\n",
        "        raise ValueError(\"Lambda must be positive for Poisson distribution.\")\n",
        "\n",
        "    print(f\"\\n--- Poisson CDF Calculation (Lambda = {lambda_val}) ---\")\n",
        "\n",
        "    if k_value is not None:\n",
        "        if not isinstance(k_value, int) or k_value < 0:\n",
        "            raise ValueError(\"k_value must be a non-negative integer.\")\n",
        "        cdf_at_k = poisson.cdf(k_value, mu=lambda_val)\n",
        "        print(f\"P(X <= {k_value}) = {cdf_at_k:.4f}\")\n",
        "        print(f\"Interpretation: There is a {cdf_at_k*100:.2f}% chance of observing {k_value} or fewer events in the given interval.\")\n",
        "    else:\n",
        "        # Plot CDF for a range of relevant values\n",
        "        # Determine a reasonable upper bound for plotting based on lambda\n",
        "        max_k = int(poisson.ppf(0.999, mu=lambda_val)) + 1 # k value where CDF is ~0.999\n",
        "        if max_k < 5: # Ensure at least a few points are plotted\n",
        "            max_k = 5\n",
        "\n",
        "        k_values = np.arange(0, max_k + 1)\n",
        "        cdf_values = poisson.cdf(k_values, mu=lambda_val)\n",
        "\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        plt.step(k_values, cdf_values, where='post', color='darkblue', linestyle='-', marker='o', markersize=5)\n",
        "        plt.title(f'Cumulative Distribution Function (CDF) of Poisson Distribution (λ={lambda_val})')\n",
        "        plt.xlabel('Number of Events (k)')\n",
        "        plt.ylabel('P(X <= k)')\n",
        "        plt.xticks(k_values)\n",
        "        plt.yticks(np.arange(0, 1.1, 0.1))\n",
        "        plt.grid(True, linestyle='--', alpha=0.7)\n",
        "        plt.show()\n",
        "\n",
        "        print(\"\\nInterpretation: The CDF plot shows the cumulative probability of observing 'k' or fewer events.\")\n",
        "        print(f\"For instance, P(X <= 0) is {cdf_values[0]:.4f}, P(X <= 1) is {cdf_values[1]:.4f}, and so on.\")\n",
        "        print(\"As 'k' increases, the cumulative probability approaches 1.\")\n",
        "\n",
        "# Example usage:\n",
        "calculate_and_interpret_poisson_cdf(lambda_val=3)\n",
        "calculate_and_interpret_poisson_cdf(lambda_val=3, k_value=2)\n",
        "calculate_and_interpret_poisson_cdf(lambda_val=0.8, k_value=0)\n",
        "calculate_and_interpret_poisson_cdf(lambda_val=5)\n",
        "20. Simulate a random variable using a continuous uniform distribution and calculate its expected value.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def simulate_and_calculate_expected_value_uniform(a, b, num_simulations=100000):\n",
        "    \"\"\"\n",
        "    Simulates random variables from a continuous uniform distribution\n",
        "    and calculates its empirical expected value.\n",
        "\n",
        "    Args:\n",
        "        a (float): Lower bound of the uniform distribution.\n",
        "        b (float): Upper bound of the uniform distribution.\n",
        "        num_simulations (int): Number of random variables to simulate.\n",
        "\n",
        "    Returns:\n",
        "        float: The empirical expected value.\n",
        "    \"\"\"\n",
        "    if a >= b:\n",
        "        raise ValueError(\"Lower bound 'a' must be less than upper bound 'b'.\")\n",
        "\n",
        "    # Simulate random variables from a continuous uniform distribution\n",
        "    simulated_data = np.random.uniform(low=a, high=b, size=num_simulations)\n",
        "\n",
        "    # Calculate the empirical expected value (mean of simulated data)\n",
        "    empirical_expected_value = np.mean(simulated_data)\n",
        "\n",
        "    # Calculate the theoretical expected value for a continuous uniform distribution\n",
        "    theoretical_expected_value = (a + b) / 2\n",
        "\n",
        "    print(f\"--- Continuous Uniform Distribution Simulation ---\")\n",
        "    print(f\"Distribution Range: [{a}, {b}]\")\n",
        "    print(f\"Number of Simulations: {num_simulations}\")\n",
        "    print(f\"Theoretical Expected Value: {theoretical_expected_value:.4f}\")\n",
        "    print(f\"Empirical Expected Value (from simulation): {empirical_expected_value:.4f}\")\n",
        "\n",
        "    return empirical_expected_value\n",
        "\n",
        "# Example usage:\n",
        "simulate_and_calculate_expected_value_uniform(a=0, b=1)\n",
        "simulate_and_calculate_expected_value_uniform(a=5, b=15, num_simulations=500000)\n",
        "21. Write a Python program to compare the standard deviations of two datasets and visualize the difference.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def compare_std_devs(dataset1, dataset2, name1=\"Dataset 1\", name2=\"Dataset 2\"):\n",
        "    \"\"\"\n",
        "    Compares the standard deviations of two datasets and visualizes their distributions.\n",
        "\n",
        "    Args:\n",
        "        dataset1 (array-like): The first dataset.\n",
        "        dataset2 (array-like): The second dataset.\n",
        "        name1 (str): Name for the first dataset (for plotting/printing).\n",
        "        name2 (str): Name for the second dataset (for plotting/printing).\n",
        "    \"\"\"\n",
        "    data1 = np.array(dataset1)\n",
        "    data2 = np.array(dataset2)\n",
        "\n",
        "    std1 = np.std(data1)\n",
        "    std2 = np.std(data2)\n",
        "\n",
        "    print(f\"--- Standard Deviation Comparison ---\")\n",
        "    print(f\"{name1} Standard Deviation: {std1:.4f}\")\n",
        "    print(f\"{name2} Standard Deviation: {std2:.4f}\")\n",
        "\n",
        "    if std1 > std2:\n",
        "        print(f\"Conclusion: {name1} has a larger standard deviation, indicating greater spread/variability.\")\n",
        "    elif std2 > std1:\n",
        "        print(f\"Conclusion: {name2} has a larger standard deviation, indicating greater spread/variability.\")\n",
        "    else:\n",
        "        print(f\"Conclusion: Both datasets have approximately the same standard deviation.\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot histograms\n",
        "    plt.hist(data1, bins=30, density=True, alpha=0.6, label=f'{name1} (Std Dev: {std1:.2f})', color='skyblue')\n",
        "    plt.hist(data2, bins=30, density=True, alpha=0.6, label=f'{name2} (Std Dev: {std2:.2f})', color='lightcoral')\n",
        "\n",
        "    # Add vertical lines for means for better context\n",
        "    plt.axvline(np.mean(data1), color='blue', linestyle='dashed', linewidth=1.5, label=f'{name1} Mean: {np.mean(data1):.2f}')\n",
        "    plt.axvline(np.mean(data2), color='red', linestyle='dashed', linewidth=1.5, label=f'{name2} Mean: {np.mean(data2):.2f}')\n",
        "\n",
        "    plt.title('Comparison of Data Distributions and Standard Deviations')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Example Usage:\n",
        "np.random.seed(42)\n",
        "data_set_A = np.random.normal(loc=50, scale=10, size=500) # Higher std dev\n",
        "data_set_B = np.random.normal(loc=55, scale=5, size=500)  # Lower std dev, different mean\n",
        "\n",
        "compare_std_devs(data_set_A, data_set_B, name1=\"Dataset A (Higher Variability)\", name2=\"Dataset B (Lower Variability)\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "np.random.seed(123)\n",
        "data_set_C = np.random.normal(loc=10, scale=2, size=300)\n",
        "data_set_D = np.random.normal(loc=12, scale=2.1, size=300) # Similar std dev\n",
        "compare_std_devs(data_set_C, data_set_D, name1=\"Dataset C\", name2=\"Dataset D\")\n",
        "22. Calculate the range and interquartile range (IQR) of a dataset generated from a normal distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def calculate_range_and_iqr(dataset):\n",
        "    \"\"\"\n",
        "    Calculates the range and Interquartile Range (IQR) of a dataset.\n",
        "\n",
        "    Args:\n",
        "        dataset (array-like): The input dataset.\n",
        "\n",
        "    Returns:\n",
        "        tuple: (data_range, iqr)\n",
        "    \"\"\"\n",
        "    data = np.array(dataset)\n",
        "\n",
        "    if len(data) == 0:\n",
        "        print(\"Dataset is empty.\")\n",
        "        return None, None\n",
        "\n",
        "    # Calculate Range\n",
        "    data_range = np.max(data) - np.min(data)\n",
        "\n",
        "    # Calculate Quartiles\n",
        "    Q1 = np.percentile(data, 25) # 25th percentile (first quartile)\n",
        "    Q3 = np.percentile(data, 75) # 75th percentile (third quartile)\n",
        "\n",
        "    # Calculate IQR\n",
        "    iqr = Q3 - Q1\n",
        "\n",
        "    print(f\"--- Descriptive Statistics ---\")\n",
        "    print(f\"Dataset Size: {len(data)}\")\n",
        "    print(f\"Min Value: {np.min(data):.2f}\")\n",
        "    print(f\"Max Value: {np.max(data):.2f}\")\n",
        "    print(f\"Calculated Range: {data_range:.2f}\")\n",
        "    print(f\"First Quartile (Q1): {Q1:.2f}\")\n",
        "    print(f\"Third Quartile (Q3): {Q3:.2f}\")\n",
        "    print(f\"Calculated Interquartile Range (IQR): {iqr:.2f}\")\n",
        "\n",
        "    return data_range, iqr\n",
        "\n",
        "# Example Usage:\n",
        "np.random.seed(42)\n",
        "# Generate data from a normal distribution\n",
        "normal_data = np.random.normal(loc=100, scale=15, size=200)\n",
        "\n",
        "data_range_val, iqr_val = calculate_range_and_iqr(normal_data)\n",
        "\n",
        "print(\"\\n\" + \"=\"*40 + \"\\n\")\n",
        "\n",
        "# Another example with different parameters\n",
        "np.random.seed(123)\n",
        "normal_data_2 = np.random.normal(loc=50, scale=5, size=100)\n",
        "data_range_val_2, iqr_val_2 = calculate_range_and_iqr(normal_data_2)\n",
        "23. Implement Z-score normalization on a dataset and visualize its transformation.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def z_score_normalize_and_visualize(dataset, original_name=\"Original Data\", normalized_name=\"Z-score Normalized Data\"):\n",
        "    \"\"\"\n",
        "    Applies Z-score normalization (standardization) to a dataset\n",
        "    and visualizes the original and transformed distributions.\n",
        "\n",
        "    Args:\n",
        "        dataset (array-like): The input dataset.\n",
        "        original_name (str): Name for the original dataset in plots/prints.\n",
        "        normalized_name (str): Name for the normalized dataset in plots/prints.\n",
        "    Returns:\n",
        "        numpy.ndarray: The Z-score normalized dataset.\n",
        "    \"\"\"\n",
        "    data = np.array(dataset)\n",
        "\n",
        "    if len(data) == 0:\n",
        "        print(\"Dataset is empty. Cannot normalize.\")\n",
        "        return np.array([])\n",
        "    if np.std(data) == 0:\n",
        "        print(\"Standard deviation is zero. Cannot perform Z-score normalization.\")\n",
        "        return data # Return original data if std dev is 0\n",
        "\n",
        "    original_mean = np.mean(data)\n",
        "    original_std = np.std(data)\n",
        "\n",
        "    # Z-score normalization\n",
        "    normalized_data = (data - original_mean) / original_std\n",
        "\n",
        "    print(f\"--- Z-score Normalization ---\")\n",
        "    print(f\"{original_name} Mean: {original_mean:.4f}\")\n",
        "    print(f\"{original_name} Std Dev: {original_std:.4f}\")\n",
        "    print(f\"{normalized_name} Mean: {np.mean(normalized_data):.4f} (should be close to 0)\")\n",
        "    print(f\"{normalized_name} Std Dev: {np.std(normalized_data):.4f} (should be close to 1)\")\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(12, 6))\n",
        "\n",
        "    # Plot original data histogram\n",
        "    plt.subplot(1, 2, 1) # 1 row, 2 columns, first plot\n",
        "    plt.hist(data, bins=30, density=True, alpha=0.7, color='skyblue', edgecolor='black')\n",
        "    plt.title(f'{original_name}\\nMean={original_mean:.2f}, Std Dev={original_std:.2f}')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "\n",
        "    # Plot normalized data histogram\n",
        "    plt.subplot(1, 2, 2) # 1 row, 2 columns, second plot\n",
        "    plt.hist(normalized_data, bins=30, density=True, alpha=0.7, color='lightcoral', edgecolor='black')\n",
        "    # Overlay standard normal PDF for comparison\n",
        "    x_normalized = np.linspace(min(normalized_data) - 0.5, max(normalized_data) + 0.5, 200)\n",
        "    pdf_standard_normal = norm.pdf(x_normalized, 0, 1)\n",
        "    plt.plot(x_normalized, pdf_standard_normal, color='blue', linestyle='--', linewidth=2, label='Standard Normal PDF')\n",
        "    plt.title(f'{normalized_name}\\nMean={np.mean(normalized_data):.2f}, Std Dev={np.std(normalized_data):.2f}')\n",
        "    plt.xlabel('Z-score')\n",
        "    plt.ylabel('Density')\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.legend()\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "    return normalized_data\n",
        "\n",
        "# Example Usage:\n",
        "np.random.seed(42)\n",
        "original_dataset = np.random.normal(loc=150, scale=25, size=1000)\n",
        "normalized_dataset = z_score_normalize_and_visualize(original_dataset)\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Another example with a different distribution (though Z-score normalization can be applied to any data)\n",
        "np.random.seed(123)\n",
        "original_dataset_2 = np.random.exponential(scale=10, size=500) # Non-normal distribution\n",
        "normalized_dataset_2 = z_score_normalize_and_visualize(original_dataset_2, original_name=\"Original Exponential Data\")\n",
        "24. Write a Python function to calculate the skewness and kurtosis of a dataset generated from a normal distribution.\n",
        "\n",
        "Python\n",
        "\n",
        "import numpy as np\n",
        "from scipy.stats import skew, kurtosis\n",
        "import matplotlib.pyplot as plt\n",
        "from scipy.stats import norm\n",
        "\n",
        "def calculate_skewness_kurtosis_and_visualize(dataset, dataset_name=\"Dataset\"):\n",
        "    \"\"\"\n",
        "    Calculates the skewness and kurtosis of a dataset and visualizes its histogram\n",
        "    compared to a theoretical normal distribution.\n",
        "\n",
        "    Args:\n",
        "        dataset (array-like): The input dataset.\n",
        "        dataset_name (str): Name of the dataset for display.\n",
        "    \"\"\"\n",
        "    data = np.array(dataset)\n",
        "\n",
        "    if len(data) < 2: # Skewness/Kurtosis require at least 2 points (for std dev)\n",
        "        print(\"Dataset too small to calculate skewness and kurtosis.\")\n",
        "        return\n",
        "\n",
        "    # Calculate skewness\n",
        "    # skew() function defaults to bias=True (population skewness), use bias=False for sample skewness\n",
        "    data_skewness = skew(data, bias=False)\n",
        "\n",
        "    # Calculate kurtosis\n",
        "    # kurtosis() function defaults to fisher=True (excess kurtosis), use fisher=False for Pearson kurtosis\n",
        "    # Excess kurtosis is 0 for a normal distribution\n",
        "    data_kurtosis = kurtosis(data, fisher=True, bias=False)\n",
        "\n",
        "    print(f\"--- Skewness and Kurtosis for {dataset_name} ---\")\n",
        "    print(f\"Skewness: {data_skewness:.4f}\")\n",
        "    print(f\"Kurtosis (Excess): {data_kurtosis:.4f}\")\n",
        "\n",
        "    # Interpretation\n",
        "    print(\"\\nInterpretation:\")\n",
        "    print(\"Skewness:\")\n",
        "    if data_skewness > 0.5:\n",
        "        print(\"  * Positively skewed (right-skewed): The tail on the right side is longer or fatter.\")\n",
        "    elif data_skewness < -0.5:\n",
        "        print(\"  * Negatively skewed (left-skewed): The tail on the left side is longer or fatter.\")\n",
        "    else:\n",
        "        print(\"  * Roughly symmetrical (close to 0): The data is fairly symmetrical around its mean.\")\n",
        "\n",
        "    print(\"\\nKurtosis (Excess):\")\n",
        "    if data_kurtosis > 0.5:\n",
        "        print(\"  * Leptokurtic: The distribution has heavier tails and a sharper peak than a normal distribution.\")\n",
        "    elif data_kurtosis < -0.5:\n",
        "        print(\"  * Platykurtic: The distribution has lighter tails and a flatter peak than a normal distribution.\")\n",
        "    else:\n",
        "        print(\"  * Mesokurtic (close to 0): The distribution has a similar peakedness to a normal distribution.\")\n",
        "\n",
        "\n",
        "    # Visualization\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.hist(data, bins=30, density=True, alpha=0.7, color='lightgreen', edgecolor='black', label='Actual Data Histogram')\n",
        "\n",
        "    # Overlay theoretical normal distribution for comparison\n",
        "    mean_data = np.mean(data)\n",
        "    std_data = np.std(data)\n",
        "    x = np.linspace(min(data), max(data), 500)\n",
        "    pdf_normal = norm.pdf(x, loc=mean_data, scale=std_data)\n",
        "    plt.plot(x, pdf_normal, color='red', linestyle='--', linewidth=2, label='Theoretical Normal PDF')\n",
        "\n",
        "    plt.title(f'Distribution of {dataset_name}\\nSkewness={data_skewness:.2f}, Kurtosis={data_kurtosis:.2f}')\n",
        "    plt.xlabel('Value')\n",
        "    plt.ylabel('Density')\n",
        "    plt.legend()\n",
        "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "    plt.show()\n",
        "\n",
        "# Example Usage:\n",
        "np.random.seed(42)\n",
        "# Data generated from a normal distribution should have skewness and kurtosis close to 0\n",
        "normal_dataset = np.random.normal(loc=100, scale=10, size=1000)\n",
        "calculate_skewness_kurtosis_and_visualize(normal_dataset, dataset_name=\"Normally Distributed Data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Example with skewed data (e.g., exponential distribution)\n",
        "np.random.seed(123)\n",
        "skewed_dataset = np.random.exponential(scale=5, size=1000)\n",
        "calculate_skewness_kurtosis_and_visualize(skewed_dataset, dataset_name=\"Exponentially Distributed Data\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60 + \"\\n\")\n",
        "\n",
        "# Example with heavy-tailed data (e.g., Cauchy distribution - difficult to sample due to undefined mean/variance)\n",
        "# Let's simulate some data that *might* exhibit higher kurtosis by combining two normals\n",
        "np.random.seed(789)\n",
        "heavy_tailed_data = np.concatenate([np.random.normal(0, 1, 500), np.random.normal(0, 5, 500)])\n",
        "calculate_skewness_kurtosis_and_visualize(heavy_tailed_data, dataset_name=\"Heavy-Tailed Data\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    }
  ]
}